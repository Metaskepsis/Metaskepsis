{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wias\\Langgraph_Manuscript_Workflows\\Langgraph_Manuscript_Workflows\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from simple_workflows import *\n",
    "from simple_tools import *\n",
    "from workflows_as_tools import *\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receptionist: The following has been forwarded to the arxiv_retriever:  I'll create queries for each paper and send them to the retriever.\n",
      "\n",
      "Here's the first query:\n",
      "\n",
      "`\"An interpolating distance between optimal transport and Fisher-Rao metrics\"`\n",
      "\n",
      "Please wait for the response before I proceed to the next query.\n",
      "Retriever: I am going to call  get_id_from_url\n",
      "Tool_executor: I am going to executeget_id_from_urlwith{'url': 'https://export.arxiv.org/api/query?search_query=An_interpolating_distance_between_optimal_transport_and_Fisher-Rao_metrics&max_results=5'}\n",
      "Scraper: I got an error, going back to the arxiv_retriever\n",
      "Retriever:I am reporting back to the arxiv_receptionist withNo paper found for the query. Let's try with a different query.\n",
      "Reporting to receptionist\n",
      "Receptionist: The following has been forwarded to the arxiv_retriever:  Here's a revised query:\n",
      "\n",
      "`\"interpolating distance between optimal transport Fisher-Rao metrics\"`\n",
      "\n",
      "Please wait for the response.\n",
      "Retriever: I am going to call  get_id_from_url\n",
      "Tool_executor: I am going to executeget_id_from_urlwith{'url': 'https://export.arxiv.org/api/query?search_query=interpolating+distance+between+optimal+transport+Fisher-Rao+metrics&max_results=5'}\n",
      "Scraper: I got the following paperThe most relevant arXiv paper to the query is \"An Interpolating Distance between Optimal Transport and Fisher-Rao\" and its id-url is \"http://arxiv.org/abs/1506.06430v2\".\n",
      "Retriever: I am going to call  download_pdf\n",
      "Tool_executor: I am going to executedownload_pdfwith{'id': '1506.06430v2', 'title': 'Interpolating_Distance_Optimal_Transport'}\n",
      "Retriever:I am reporting back to the arxiv_receptionist withThe paper with the title 'An Interpolating Distance between Optimal Transport and Fisher-Rao' has successfully been downloaded.\n",
      "Reporting to receptionist\n",
      "Receptionist: The following has been forwarded to the arxiv_retriever:  Now, let's move on to the second query.\n",
      "\n",
      "Here's the query:\n",
      "\n",
      "`\"Unbalanced optimal transport Dynamic and Kantorovich formulations\"`\n",
      "\n",
      "Please wait for the response.\n",
      "Retriever: I am going to call  get_id_from_url\n",
      "Tool_executor: I am going to executeget_id_from_urlwith{'url': 'https://export.arxiv.org/api/query?search_query=Unbalanced+optimal+transport+Dynamic+and+Kantorovich+formulations&max_results=5'}\n",
      "Scraper: I got the following paperThe most relevant arXiv paper to the query is \"Unbalanced Optimal Transport: Dynamic and Kantorovich Formulation\" and its id-url is \"http://arxiv.org/abs/1508.05216v3\".\n",
      "Retriever: I am going to call  download_pdf\n",
      "Tool_executor: I am going to executedownload_pdfwith{'id': '1508.05216', 'title': 'Unbalanced_Optimal_Transport'}\n",
      "Retriever:I am reporting back to the arxiv_receptionist withThe paper with the title 'Unbalanced Optimal Transport: Dynamic and Kantorovich Formulation' has sucessfully been downloaded.\n",
      "Reporting to receptionist\n",
      "Receptionist**Final Report:**\n",
      "\n",
      "The following papers were successfully retrieved:\n",
      "\n",
      "1. 'An Interpolating Distance between Optimal Transport and Fisher-Rao'\n",
      "2. 'Unbalanced Optimal Transport: Dynamic and Kantorovich Formulation'\n",
      "\n",
      "We are done.\n",
      "**Final Report:**\n",
      "\n",
      "The following papers were successfully retrieved:\n",
      "\n",
      "1. 'An Interpolating Distance between Optimal Transport and Fisher-Rao'\n",
      "2. 'Unbalanced Optimal Transport: Dynamic and Kantorovich Formulation'\n",
      "\n",
      "We are done.\n"
     ]
    }
   ],
   "source": [
    "### This is a multiagent workflow. Its purpose is to retrieve a collection of papers from arxiv.\n",
    "### The input is a 'list' (in the sense of everyday speech) with each element being the name or keywords around the paper (check the bib file).\n",
    "### Under the hood it searches for the most relevant paper and downlads it in the pdf folder.\n",
    "### In the end you get a report of the papers that were retrieved.\n",
    "### This needs an OpenAI API key to work. There are ways around it, but you need to use a Chat method that uses tools. \n",
    "### You can try your own bibliography here. example bib={1. life of brian, 2. death rebearth 3.  time  illustion wondering face }\n",
    "\n",
    "input={\"receptionist_retriever_history\":[HumanMessage(content=\"\")],\n",
    "    \"last_action_outcome\":[HumanMessage(content=\"\")],\n",
    "    \"metadata\":HumanMessage(content=\" \"),\n",
    "    \"article_keywords\":HumanMessage(content=\" \"),\n",
    "    \"title_of_retrieved_paper\":HumanMessage(content=\" \"),\n",
    "    \"should_I_clean\": False}\n",
    "input[\"receptionist_retriever_history\"][0]=HumanMessage(content=\"Please fetch me the following papers:\" + \"1. An interpolating distance between optimal transport and Fisher-Rao metrics , 2 Unbalanced optimal transport: Dynamic and Kantorovich formulations_?\")\n",
    "\n",
    "### Here You can set different agents to staff the workflow. The default is arxiv_retriever_workflow(retrieval_model=ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0), \n",
    "### cleaner_model=ChatNVIDIA(model=\"meta/llama3-70b-instruct\"), receptionist_model=ChatNVIDIA(model=\"meta/llama3-70b-instruct\"))\n",
    "### the retrieval agents needs tools and ChatNVIDIA is still in development. \n",
    "\n",
    "retrieve_app=ArxivRetrievalWorkflow()\n",
    "retrieve_app=retrieve_app.create_workflow()\n",
    "retrieve_app=retrieve_app.compile()\n",
    "state=retrieve_app.invoke(input,{\"recursion_limit\": 100})    \n",
    "print(state[\"receptionist_retriever_history\"][-1].content)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Same as before but in a form of a tool. Just for testing purposes.\n",
    "ArxivRetrievalTool=ArxivRetrievalToolClass()\n",
    "ArxivRetrievalTool=StructuredTool(name=\"ArxivRetrievalTool\",func=ArxivRetrievalTool.retrieve_bib,args_schema=ArxivRetrievalInput,\n",
    "                           description=ArxivRetrievalTool.description)\n",
    "ArxivRetrievalTool.invoke(\"1.Creatine for gains, 2. Is time relative or relativety had its time\")\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### It takes the name of a pdf located in the folder files\\pdfs as inpup and creates two markdowns, one with mupdf and one with nougat.\n",
    "pdf_to_markdown.invoke(\"Li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This tool takes two version of the same file and creates a new one that actually has the best of both worlds\n",
    "### As it is, it just fixes an issue with citation format with nougat by leveraging the ocr one gets from mupdf\n",
    "###(which is lower quality but with the right format). With a little bit of prompting tweeking it can get more\n",
    "### general tasks of this nature. This tool needs an embeding mechanism as well. The reason is to locate the pages\n",
    "### in the second file that correspond to the pages in the first.\n",
    "\n",
    "ocr_enhancer_app=OcrEnchancingWorkflow()\n",
    "ocr_enhancer_app=ocr_enhancer_app.create_workflow()\n",
    "ocr_enhancer_app=ocr_enhancer_app.compile()\n",
    "input={\"main_text_filename\": HumanMessage(content=\"Li\"), \"supporting_text_filename\": HumanMessage(content=\"mu_Li\")}\n",
    "state=ocr_enhancer_app.invoke(input)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Same as before but in a form of a tool. Just for testing purposes.\n",
    "\n",
    "OcrEnhancingTool=OcrEnhancingToolClass()\n",
    "OcrEnhancingTool=StructuredTool(name=\"OcrEnhancingTool\",func=OcrEnhancingTool.ocr_enhance,args_schema=OcrEnhancingInput)\n",
    "OcrEnhancingTool.invoke({\"main_text_filename\": \"Li\", \"supporting_text_filename\": \"mu_Li\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The idea of this chain/tool is to remove the proofs from a paper so it will be easier to make a summary out of it. \n",
    "### The tool uses two chains under the hood. The first stamps the pages of the text that continue a proof from the previous page.\n",
    "### The idea was to help the LLM a bit to recognize proofs. The second LLM is doint the removal.\n",
    "### From all the modules I created, this was the most unsucessful one. Even with strong LLMs like GPT-4o and Opus, I had partial results.\n",
    "### I welcome anyone who can improve the prompt for this tool.\n",
    "proof_remover_app=ProofRemovingWorkflow()\n",
    "proof_remover_app=proof_remover_app.create_workflow()\n",
    "proof_remover_app=proof_remover_app.compile()\n",
    "input={\"main_text_filename\": HumanMessage(content=\"Li\"),\"file\":[\"\"],\"report\":HumanMessage(content=\"\")}\n",
    "state=proof_remover_app.invoke(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [02:44<00:00,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proofs were remove and the resulted file is named Li_without_proofs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The proofs were remove and the resulted file is named Li_without_proofs'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Same as before but in a form of a tool. Just for testing purposes.\n",
    "\n",
    "ProofRemoverTool=ProofRemovalToolClass()\n",
    "ProofRemoverTool=StructuredTool(name=\"ProofRemovalTool\",func=ProofRemoverTool.remove_proof,args_schema=ProofRemovalInput)\n",
    "ProofRemoverTool.invoke({\"main_text_filename\": \"Li\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This tool takes a text found in the folder files/markdowns and creates a set of keywords and a summary. in a form of a string and extracts the keywords and summary.\n",
    "### It is preferable to use a file that doesnt contain proofs because it produces a better summary. \n",
    "input={\"main_text_filename\": HumanMessage(content=\"Li\"),\n",
    "           \"report\":HumanMessage(content=\"\"),}\n",
    "keyword_and_summary_app=KeywordAndSummaryWorkflow()\n",
    "keyword_and_summary_app=keyword_and_summary_app.create_workflow()\n",
    "keyword_and_summary_app=keyword_and_summary_app.compile()\n",
    "state=keyword_and_summary_app.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword_and_summary in progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 11/34 [01:33<03:50, 10.00s/it]"
     ]
    }
   ],
   "source": [
    "### Same as before but in a form of a tool. Just for testing purposes.\n",
    "\n",
    "KeywordAndSummaryTool=KeywordAndSummaryToolClass()\n",
    "KeywordAndSummaryTool=StructuredTool(name=\"KeywordAndSummaryTool\",func=KeywordAndSummaryTool.get_keyword_and_summary,args_schema=KeywordSummaryInput)\n",
    "KeywordAndSummaryTool.invoke({\"main_text_filename\": \"Li\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation of Li in progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/34 [00:17<09:24, 17.09s/it]"
     ]
    }
   ],
   "source": [
    "input={\"keywords_and_summary_filename\": HumanMessage(content=\"Li_keyword_and_summary\"), \"target_language\":HumanMessage\n",
    "(content=\"en\"),\"main_text_filename\": HumanMessage(content=\"Li\"), \"report\":HumanMessage}\n",
    "\n",
    "translation_app=TranslationWorkflow()\n",
    "translation_app=translation_app.create_workflow()\n",
    "translation_app=translation_app.compile()\n",
    "state=translation_app.invoke(input)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TranslationTool =TranslationToolClass()\n",
    "    \n",
    "TranslationTool=StructuredTool(name=\"TranslationTool\",func=TranslationTool.translate_file,args_schema=TranslatorInput,\n",
    "                           description=TranslationTool.description)\n",
    "TranslationTool.invoke(input={\"keywords_and_summary_filename\":\"\",\"target_language\":\"en\",\"main_text_filename\":\"Li\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input={\"auxilary_filename\": HumanMessage(content=\"Li_keyword_and_summary\"), \"extraction_type\":HumanMessage(content=\"All of them\"),\"main_text_filename\": HumanMessage(content=\"Li\"), \n",
    "\"report\":HumanMessage(content=\"\")}\n",
    "\n",
    "citation_extraction_app=CitationExtractionWorkflow()\n",
    "citation_extraction_app=citation_extraction_app.create_workflow()\n",
    "citation_extraction_app=citation_extraction_app.compile()\n",
    "state=citation_extraction_app.invoke(input)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CitationExtractionToolClass.extract_citations() got an unexpected keyword argument 'auxilary_filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\wias\\Langgraph_Manuscript_Workflows\\playground.ipynb Cell 15\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wias/Langgraph_Manuscript_Workflows/playground.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m CitationExtractionTool\u001b[39m=\u001b[39mCitationExtractionToolClass()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wias/Langgraph_Manuscript_Workflows/playground.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m CitationExtractionTool\u001b[39m=\u001b[39mStructuredTool(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCitationExtractionTool\u001b[39m\u001b[39m\"\u001b[39m,func\u001b[39m=\u001b[39mCitationExtractionTool\u001b[39m.\u001b[39mextract_citations,args_schema\u001b[39m=\u001b[39mCitationExtractorInput,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/wias/Langgraph_Manuscript_Workflows/playground.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                            description\u001b[39m=\u001b[39mCitationExtractionTool\u001b[39m.\u001b[39mdescription)  \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/wias/Langgraph_Manuscript_Workflows/playground.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m CitationExtractionTool\u001b[39m.\u001b[39;49minvoke(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mmain_text_filename\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mLi\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mextraction_type\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mAll of them\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mauxilary_filename\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mLi_keyword_and_summary\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n",
      "File \u001b[1;32mc:\\Users\\wias\\Langgraph_Manuscript_Workflows\\Langgraph_Manuscript_Workflows\\Lib\\site-packages\\langchain_core\\tools.py:260\u001b[0m, in \u001b[0;36mBaseTool.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[0;32m    254\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    255\u001b[0m     \u001b[39minput\u001b[39m: Union[\u001b[39mstr\u001b[39m, Dict],\n\u001b[0;32m    256\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    257\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    258\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    259\u001b[0m     config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m--> 260\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m    261\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[0;32m    262\u001b[0m         callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    263\u001b[0m         tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    264\u001b[0m         metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    265\u001b[0m         run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    266\u001b[0m         run_id\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mrun_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    267\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    268\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    269\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\wias\\Langgraph_Manuscript_Workflows\\Langgraph_Manuscript_Workflows\\Lib\\site-packages\\langchain_core\\tools.py:452\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_error(e)\n\u001b[1;32m--> 452\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    453\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    454\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_end(observation, color\u001b[39m=\u001b[39mcolor, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wias\\Langgraph_Manuscript_Workflows\\Langgraph_Manuscript_Workflows\\Lib\\site-packages\\langchain_core\\tools.py:409\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[0;32m    406\u001b[0m     parsed_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_input(tool_input)\n\u001b[0;32m    407\u001b[0m     tool_args, tool_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[0;32m    408\u001b[0m     observation \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 409\u001b[0m         context\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m    410\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run, \u001b[39m*\u001b[39;49mtool_args, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_kwargs\n\u001b[0;32m    411\u001b[0m         )\n\u001b[0;32m    412\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    413\u001b[0m         \u001b[39melse\u001b[39;00m context\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run, \u001b[39m*\u001b[39mtool_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtool_kwargs)\n\u001b[0;32m    414\u001b[0m     )\n\u001b[0;32m    415\u001b[0m \u001b[39mexcept\u001b[39;00m ValidationError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_validation_error:\n",
      "File \u001b[1;32mc:\\Users\\wias\\Langgraph_Manuscript_Workflows\\Langgraph_Manuscript_Workflows\\Lib\\site-packages\\langchain_core\\tools.py:750\u001b[0m, in \u001b[0;36mStructuredTool._run\u001b[1;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc:\n\u001b[0;32m    742\u001b[0m     new_argument_supported \u001b[39m=\u001b[39m signature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    743\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    744\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\n\u001b[0;32m    745\u001b[0m             \u001b[39m*\u001b[39margs,\n\u001b[0;32m    746\u001b[0m             callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    747\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    748\u001b[0m         )\n\u001b[0;32m    749\u001b[0m         \u001b[39mif\u001b[39;00m new_argument_supported\n\u001b[1;32m--> 750\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    751\u001b[0m     )\n\u001b[0;32m    752\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTool does not support sync\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: CitationExtractionToolClass.extract_citations() got an unexpected keyword argument 'auxilary_filename'"
     ]
    }
   ],
   "source": [
    "CitationExtractionTool=CitationExtractionToolClass()\n",
    "\n",
    "CitationExtractionTool=StructuredTool(name=\"CitationExtractionTool\",func=CitationExtractionTool.extract_citations,args_schema=CitationExtractorInput,\n",
    "                           description=CitationExtractionTool.description)  \n",
    "\n",
    "CitationExtractionTool.invoke(input={\"main_text_filename\":\"Li\",\"extraction_type\":\"All of them\",\"auxilary_filename\":\"Li_keyword_and_summary\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaios",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
