{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\artno\\anaconda3\\envs\\nvidia\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from simple_workflows import *\n",
    "from simple_tools import *\n",
    "from workflows_as_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is a multiagent workflow. Its purpose is to retrieve a collection of papers from arxiv.\n",
    "### The input is a 'list' (in the sense of everyday speech) with each element being the name or keywords around the paper (check the bib file).\n",
    "### Under the hood it searches for the most relevant paper and downlads it in the pdf folder.\n",
    "### In the end you get a report of the papers that were retrieved.\n",
    "### This needs an OpenAI API key to work. There are ways around it, but you need to use a Chat method that uses tools. \n",
    "### You can try your own bibliography here. example bib={1. life of brian, 2. death rebearth 3.  time  illustion wondering face }\n",
    "\n",
    "input={\"receptionist_retriever_history\":[HumanMessage(content=\"\")],\n",
    "    \"last_action_outcome\":[HumanMessage(content=\"\")],\n",
    "    \"metadata\":HumanMessage(content=\" \"),\n",
    "    \"article_keywords\":HumanMessage(content=\" \"),\n",
    "    \"title_of_retrieved_paper\":HumanMessage(content=\" \"),\n",
    "    \"should_I_clean\": False}\n",
    "input[\"receptionist_retriever_history\"][0]=HumanMessage(content=\"Please fetch me the following papers:\" + \"1 mitochondira are really small? , 2 is life really short?\")\n",
    "\n",
    "### Here You can set different agents to staff the workflow. The default is arxiv_retriever_workflow(retrieval_model=ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0), \n",
    "### cleaner_model=ChatNVIDIA(model=\"meta/llama3-70b-instruct\"), receptionist_model=ChatNVIDIA(model=\"meta/llama3-70b-instruct\"))\n",
    "### the retrieval agents needs tools and ChatNVIDIA is still in development. \n",
    "\n",
    "retrieve_app=ArxivRetrievalWorkflow()\n",
    "retrieve_app=retrieve_app.create_workflow()\n",
    "retrieve_app=retrieve_app.compile()\n",
    "state=retrieve_app.invoke(input,{\"recursion_limit\": 100})    \n",
    "print(state[\"receptionist_retriever_history\"][-1].content)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Same as before but in a form of a tool. Just for testing purposes.\n",
    "ArxivRetrievalTool=ArxivRetrievalToolClass()\n",
    "ArxivRetrievalTool=StructuredTool(name=\"ArxivRetrievalTool\",func=ArxivRetrievalTool.retrieve_bib,args_schema=ArxivRetrievalInput,\n",
    "                           description=ArxivRetrievalTool.description)\n",
    "ArxivRetrievalTool.invoke(\"1.Creatine for gains, 2. Is time relative or relativety had its time\")\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### It takes the name of a pdf located in the folder files\\pdfs as inpup and creates two markdowns, one with mupdf and one with nougat.\n",
    "pdf_to_markdown.invoke(\"Li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This tool takes two version of the same file and creates a new one that actually has the best of both worlds\n",
    "### As it is, it just fixes an issue with citation format with nougat by leveraging the ocr one gets from mupdf\n",
    "###(which is lower quality but with the right format). With a little bit of prompting tweeking it can get more\n",
    "### general tasks of this nature. This tool needs an embeding mechanism as well. The reason is to locate the pages\n",
    "### in the second file that correspond to the pages in the first.\n",
    "\n",
    "ocr_enhancer_app=OcrEnchancingWorkflow()\n",
    "ocr_enhancer_app=ocr_enhancer_app.create_workflow()\n",
    "ocr_enhancer_app=ocr_enhancer_app.compile()\n",
    "input={\"main_text_filename\": HumanMessage(content=\"Li\"), \"supporting_text_filename\": HumanMessage(content=\"mu_Li\")}\n",
    "state=ocr_enhancer_app.invoke(input)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Same as before but in a form of a tool. Just for testing purposes.\n",
    "\n",
    "OcrEnhancingTool=OcrEnhancingToolClass()\n",
    "OcrEnhancingTool=StructuredTool(name=\"OcrEnhancingTool\",func=OcrEnhancingTool.ocr_enhance,args_schema=OcrEnhancingInput)\n",
    "OcrEnhancingTool.invoke({\"main_text_filename\": \"Li\", \"supporting_text_filename\": \"mu_Li\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stamping phase is initiated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:29<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proof removal in progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [02:44<00:00,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proofs were remove and the resulted file is named Li_without_proofs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### The idea of this chain/tool is to remove the proofs from a paper so it will be easier to make a summary out of it. \n",
    "### The tool uses two chains under the hood. The first stamps the pages of the text that continue a proof from the previous page.\n",
    "### The idea was to help the LLM a bit to recognize proofs. The second LLM is doint the removal.\n",
    "### From all the modules I created, this was the most unsucessful one. Even with strong LLMs like GPT-4o and Opus, I had partial results.\n",
    "### I welcome anyone who can improve the prompt for this tool.\n",
    "proof_remover_app=ProofRemovingWorkflow()\n",
    "proof_remover_app=proof_remover_app.create_workflow()\n",
    "proof_remover_app=proof_remover_app.compile()\n",
    "input={\"main_text_filename\": HumanMessage(content=\"Li\"),\"file\":[\"\"],\"report\":HumanMessage(content=\"\")}\n",
    "state=proof_remover_app.invoke(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ProofRemovalToolClass.remove_proof() got an unexpected keyword argument 'main_text_filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m ProofRemoverTool\u001b[38;5;241m=\u001b[39mProofRemovalToolClass()\n\u001b[0;32m      4\u001b[0m ProofRemoverTool\u001b[38;5;241m=\u001b[39mStructuredTool(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProofRemovalTool\u001b[39m\u001b[38;5;124m\"\u001b[39m,func\u001b[38;5;241m=\u001b[39mProofRemoverTool\u001b[38;5;241m.\u001b[39mremove_proof,args_schema\u001b[38;5;241m=\u001b[39mProofRemovalInput)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mProofRemoverTool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmain_text_filename\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\artno\\anaconda3\\envs\\nvidia\\Lib\\site-packages\\langchain_core\\tools.py:260\u001b[0m, in \u001b[0;36mBaseTool.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, Dict],\n\u001b[0;32m    256\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    259\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m--> 260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\artno\\anaconda3\\envs\\nvidia\\Lib\\site-packages\\langchain_core\\tools.py:452\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e)\n\u001b[1;32m--> 452\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    454\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(observation, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\artno\\anaconda3\\envs\\nvidia\\Lib\\site-packages\\langchain_core\\tools.py:409\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[0;32m    406\u001b[0m     parsed_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_input(tool_input)\n\u001b[0;32m    407\u001b[0m     tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[0;32m    408\u001b[0m     observation \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 409\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run, \u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[0;32m    414\u001b[0m     )\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error:\n",
      "File \u001b[1;32mc:\\Users\\artno\\anaconda3\\envs\\nvidia\\Lib\\site-packages\\langchain_core\\tools.py:750\u001b[0m, in \u001b[0;36mStructuredTool._run\u001b[1;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc:\n\u001b[0;32m    742\u001b[0m     new_argument_supported \u001b[38;5;241m=\u001b[39m signature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    744\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\n\u001b[0;32m    745\u001b[0m             \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    746\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    747\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    748\u001b[0m         )\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_argument_supported\n\u001b[1;32m--> 750\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m     )\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool does not support sync\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: ProofRemovalToolClass.remove_proof() got an unexpected keyword argument 'main_text_filename'"
     ]
    }
   ],
   "source": [
    "### Same as before but in a form of a tool. Just for testing purposes.\n",
    "\n",
    "ProofRemoverTool=ProofRemovalToolClass()\n",
    "ProofRemoverTool=StructuredTool(name=\"ProofRemovalTool\",func=ProofRemoverTool.remove_proof,args_schema=ProofRemovalInput)\n",
    "ProofRemoverTool.invoke({\"main_text_filename\": \"Li\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This tool takes a text found in the folder files/markdowns and creates a set of keywords and a summary. in a form of a string and extracts the keywords and summary.\n",
    "### It is preferable to use a file that doesnt contain proofs because it produces a better summary. \n",
    "input={\"main_text_filename\": HumanMessage(content=\"Li\"),\n",
    "           \"report\":HumanMessage(content=\"\"),}\n",
    "keyword_and_summary_app=KeywordAndSummaryWorkflow()\n",
    "keyword_and_summary_app=keyword_and_summary_app.create_workflow()\n",
    "keyword_and_summary_app=keyword_and_summary_app.compile()\n",
    "state=keyword_and_summary_app.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword_and_summary in progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 11/34 [01:33<03:50, 10.00s/it]"
     ]
    }
   ],
   "source": [
    "### Same as before but in a form of a tool. Just for testing purposes.\n",
    "\n",
    "KeywordAndSummaryTool=KeywordAndSummaryToolClass()\n",
    "KeywordAndSummaryTool=StructuredTool(name=\"KeywordAndSummaryTool\",func=KeywordAndSummaryTool.get_keyword_and_summary,args_schema=KeywordSummaryInput)\n",
    "KeywordAndSummaryTool.invoke({\"main_text_filename\": \"Li\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input={\"keywords_and_summary_filename\": HumanMessage(content=\"markdowns\\Li_keyword_and_summary\"), \"target_language\":HumanMessage\n",
    "(content=\"en\"),\"main_text_filename\": HumanMessage(content=\"Li\"), \"report\":HumanMessage}\n",
    "\n",
    "translation_app=TranslationWorkflow()\n",
    "translation_app=translation_app.create_workflow()\n",
    "translation_app=translation_app.compile()\n",
    "state=translation_app.invoke(input)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: The keyword_and_summary file does not exist. Assuming keyword_and_summary is blank.\n",
      "Translation of Li in progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 19/34 [02:51<04:08, 16.54s/it]"
     ]
    }
   ],
   "source": [
    "TranslationTool =TranslationToolClass()\n",
    "    \n",
    "TranslationTool=StructuredTool(name=\"TranslationTool\",func=TranslationTool.translate_file,args_schema=TranslatorInput,\n",
    "                           description=TranslationTool.description)\n",
    "tools =  [TranslationTool, pdf_to_markdown]\n",
    "tool_executor=ToolExecutor(tools)\n",
    "input={\"keywords_and_summary_filename\":\"\",\"target_language\":\"en\",\"main_text_filename\":\"Li\"}\n",
    "Invocation=ToolInvocation(tool=\"TranslationTool\", tool_input=input)\n",
    "TranslationTool.invoke(input={\"keywords_and_summary_filename\":\"\",\"target_language\":\"en\",\"main_text_filename\":\"Li\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaios",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
